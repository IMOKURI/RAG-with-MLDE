import logging
import os
import time

from PIL import Image
import streamlit as st

from document_summary_index import CustomDocumentSummaryIndex
from showcase import llm_response_demo, rag_response_demo
from utils import time_since


def main():
    logging.basicConfig(level=logging.INFO)

    if "use_llm" not in st.session_state:
        st.session_state["use_llm"] = os.getenv("USE_LLM", "False").lower() in ["t", "true", "1"]

    if "llm_response" not in st.session_state:
        st.session_state["llm_response"] = None
        st.session_state["llm_response_time"] = ""
    if "rag_response" not in st.session_state:
        st.session_state["rag_response"] = None
        st.session_state["rag_response_time"] = ""

    if "architectures" not in st.session_state:
        image_pretreined = Image.open("./images/pre-trained.drawio.png")
        image_rag = Image.open("./images/rag.drawio.png")
        image_architecture = Image.open("./images/architecture.drawio.png")
        image_index_generation = Image.open("./images/index-generation.drawio.png")
        image_retrieval_index = Image.open("./images/retrieval-document-summary-index.drawio.png")

        st.session_state["architectures"] = {
            "pre-trained": image_pretreined,
            "rag": image_rag,
            "architecture": image_architecture,
            "index-generation": image_index_generation,
            "retrieval-index": image_retrieval_index,
        }

    st.set_page_config(page_title="ğŸ“ æ¤œç´¢è£œå®Œç”Ÿæˆãƒ‡ãƒ¢", layout="wide")

    st.title("ğŸ“ æ¤œç´¢è£œå®Œç”Ÿæˆãƒ‡ãƒ¢")
    st.write(
        "\n\n"
        "ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€"
        "ã‚ã‚‰ã‹ã˜ã‚å–ã‚Šè¾¼ã¾ã‚ŒãŸè¨˜äº‹ã®æƒ…å ±ã‚’å…ƒã«å›ç­”ã™ã‚‹"
        "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢è£œå®Œç”Ÿæˆ(RAG)ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚"
        "\n"
        "ä»¥ä¸‹ã®ã‚ˆã†ãªè³ªå•ã‚’å…¥åŠ›ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"
        "\n\n"
        "- HPE Swarm Learningã‚’æ§‹æˆã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚\n"
        "- HPEã®éšœå®³è€…é›‡ç”¨ã®å–ã‚Šçµ„ã¿ã«é–¢ã—ã¦ã€æœ€è¿‘å—è³ã—ãŸè³ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚\n"
        "- ãƒ©ã‚¤ãƒ€ãƒ¼ã‚«ãƒƒãƒ—ã«ã¯ã©ã®ã‚ˆã†ãªèª²é¡ŒãŒã‚ã‚Šã€HPEã¯2023å¹´ã®ãƒ©ã‚¤ãƒ€ãƒ¼ã‚«ãƒƒãƒ—ã§ã©ã®ã‚ˆã†ãªã‚µãƒãƒ¼ãƒˆã‚’ã—ã¾ã—ãŸã‹ï¼Ÿ\n"
        "\n"
    )

    if not st.session_state["use_llm"]:
        st.warning("ã“ã®ç”»é¢ã®è¡¨ç¤ºã¯ã€LLMã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã›ã‚“ã€‚å¿œç­”å†…å®¹ã¯ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("LLMã«ç›´æ¥è³ªå•ã—ãŸå ´åˆ")
        st.markdown(
            """
LLMã«ç›´æ¥è³ªå•ã™ã‚‹ã“ã¨ã§ã€ç´ æ—©ãå¿œç­”ã‚’è¿”ã™ã“ã¨ãŒã§ãã¾ã™ã€‚
"""
        )
        if st.session_state["use_llm"]:
            with st.form("llm"):
                text = st.text_area("Enter text:", "HPE Swarm Learningã‚’æ§‹æˆã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚")
                submitted_1 = st.form_submit_button("Submit")

                if submitted_1:
                    llm_query(text)
                    st.warning(
                        "LLMã¯ã€æ¤œç´¢çµæœã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€ä»˜åŠ æƒ…å ±ã‚’å‚ç…§ã—ã¦ã„ãªã„ãŸã‚ã€"
                        "å˜˜ã®æƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ (ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³)"
                    )
                    st.write(st.session_state["llm_response_time"])

                elif st.session_state["llm_response"] is not None:
                    st.info(st.session_state["llm_response"])
                    st.warning(
                        "LLMã¯ã€æ¤œç´¢çµæœã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€ä»˜åŠ æƒ…å ±ã‚’å‚ç…§ã—ã¦ã„ãªã„ãŸã‚ã€"
                        "å˜˜ã®æƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ (ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³)"
                    )
                    st.write(st.session_state["llm_response_time"])

        else:
            text = st.selectbox(
                "Select text:",
                [
                    "HPE Swarm Learningã‚’æ§‹æˆã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚",
                    "HPEã®éšœå®³è€…é›‡ç”¨ã®å–ã‚Šçµ„ã¿ã«é–¢ã—ã¦ã€æœ€è¿‘å—è³ã—ãŸè³ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚",
                    "ãƒ©ã‚¤ãƒ€ãƒ¼ã‚«ãƒƒãƒ—ã«ã¯ã©ã®ã‚ˆã†ãªèª²é¡ŒãŒã‚ã‚Šã€HPEã¯2023å¹´ã®ãƒ©ã‚¤ãƒ€ãƒ¼ã‚«ãƒƒãƒ—ã§ã©ã®ã‚ˆã†ãªã‚µãƒãƒ¼ãƒˆã‚’ã—ã¾ã—ãŸã‹ï¼Ÿ",
                ],
                key="llm",
                index=None,
            )
            st.info(llm_response_demo(text))
            st.warning(
                "LLMã¯ã€æ¤œç´¢çµæœã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€ä»˜åŠ æƒ…å ±ã‚’å‚ç…§ã—ã¦ã„ãªã„ãŸã‚ã€"
                "å˜˜ã®æƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ (ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³)"
            )

        st.image(st.session_state["architectures"]["pre-trained"], caption="LLM æ¦‚è¦å›³")

    with col2:
        st.subheader("RAGã®ä»•çµ„ã¿ã§ä»˜åŠ æƒ…å ±ã‚’å–å¾—ã—ãŸå ´åˆ")
        st.markdown(
            """
RAG (Retrieval Augmented Generation) ã¨ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«å¿…è¦ãªæ–‡ç« ã‚’æ¤œç´¢ã—ã€LLMã®å…¥åŠ›ã«è¿½åŠ ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚

ä»˜åŠ æƒ…å ±ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ­£ç¢ºãªå›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
"""
        )
        if st.session_state["use_llm"]:
            with st.form("rag"):
                text = st.text_area("Enter text:", "HPE Swarm Learningã‚’æ§‹æˆã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚")
                submitted_2 = st.form_submit_button("Submit")

                if submitted_2:
                    rag_query(text)
                    st.write(st.session_state["rag_response_time"])

                elif st.session_state["rag_response"] is not None:
                    st.info(st.session_state["rag_response"])
                    st.write(st.session_state["rag_response_time"])

        else:
            text = st.selectbox(
                "Select text:",
                [
                    "HPE Swarm Learningã‚’æ§‹æˆã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚",
                    "HPEã®éšœå®³è€…é›‡ç”¨ã®å–ã‚Šçµ„ã¿ã«é–¢ã—ã¦ã€æœ€è¿‘å—è³ã—ãŸè³ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚",
                    "ãƒ©ã‚¤ãƒ€ãƒ¼ã‚«ãƒƒãƒ—ã«ã¯ã©ã®ã‚ˆã†ãªèª²é¡ŒãŒã‚ã‚Šã€HPEã¯2023å¹´ã®ãƒ©ã‚¤ãƒ€ãƒ¼ã‚«ãƒƒãƒ—ã§ã©ã®ã‚ˆã†ãªã‚µãƒãƒ¼ãƒˆã‚’ã—ã¾ã—ãŸã‹ï¼Ÿ",
                ],
                key="rag",
                index=None,
            )
            st.info(rag_response_demo(text))

        st.image(st.session_state["architectures"]["rag"], caption="RAG (Retrieval Augmented Generation) æ¦‚è¦å›³")

        st.write(
            "ã“ã®ãƒ‡ãƒ¢ã§ã¯ã€å›ç­”ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ä»¥ä¸‹ã®æƒ…å ±ã‚’å‚ç…§ã—ã¦ã„ã¾ã™ã€‚"
            "\n\n"
            "- [HPE Swarm Learning ã¨ã¯](https://imokuri.com/blog/2022/06/hpe-swarm-learning-intro/)\n"
            "- [HPEã€æ±äº¬éƒ½ éšœå®³è€…é›‡ç”¨ã‚¨ã‚¯ã‚»ãƒ¬ãƒ³ãƒˆã‚«ãƒ³ãƒ‘ãƒ‹ãƒ¼è³ã‚’å—è³](https://prtimes.jp/main/html/rd/p/000000127.000045092.html)\n"
            "- [HPEã€é©æ–°çš„ãªãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ5Gã¨Wi-Fiã®çµ±åˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’2023 ãƒ©ã‚¤ãƒ€ãƒ¼ã‚«ãƒƒãƒ—ä¼šå ´ã«å°å…¥](https://prtimes.jp/main/html/rd/p/000000126.000045092.html)\n"
            "\n"
        )

    st.subheader("ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç´¹ä»‹")

    st.markdown(
        """
ã“ã®ãƒ‡ãƒ¢ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ã”ç´¹ä»‹ã—ã¾ã™ã€‚
"""
    )

    st.image(st.session_state["architectures"]["architecture"], caption="ãƒ‡ãƒ¢ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£")

    st.markdown(
        """
#### Index ä½œæˆ

ä»˜åŠ æƒ…å ±ã¨ã—ã¦åˆ©ç”¨ã—ãŸã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã€MLDE (Machine Learning Developement Environment) ã® ãƒãƒƒãƒæ¨è«– ã§ã€
Document Summary Index ã«ç™»éŒ²ã—ã¾ã™ã€‚

Document Summary Index ã¯ã€ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ãŸæ–‡ç« ã®è¦ç´„ã‚’ä¿æŒã—ã¦ã„ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã™ã€‚
"""
    )

    st.image(st.session_state["architectures"]["index-generation"], caption="Index ä½œæˆ")

    st.markdown(
        """
#### ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã®ç”Ÿæˆ

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ãƒãƒƒãƒã™ã‚‹è¦ç´„æ–‡ã‚’æ¢ã—ã¾ã™ã€‚

ãã®è¦ç´„æ–‡ã®å…ƒæ–‡ç« ã‚’ã€LLM ã®å…¥åŠ›ã«è¿½åŠ ã—ã¦ã€å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""
    )

    st.image(st.session_state["architectures"]["retrieval-index"], caption="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã®ç”Ÿæˆ")

    st.markdown(
        """
---
##### å‚è€ƒ: æ¤œè¨¼æ©Ÿã®ã‚¹ãƒšãƒƒã‚¯

- HW: ProLiant DL380 Gen11
- CPU: Intel(R) Xeon(R) Gold 6416H x2 (2P36C)
- Memory: 256GB
- GPU: NVIDIA H100 PCIe 80GB x1

##### å‚è€ƒ: æ¤œè¨¼æ©Ÿã®ãƒªã‚½ãƒ¼ã‚¹åˆ©ç”¨çŠ¶æ³

- CPU Memory: ç´„ 5GB
- GPU Memory: ç´„ 16GB (RAGã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒæ™‚)
- GPU Memory: ç´„ 28GB (Indexä½œæˆæ™‚)

##### åˆ©ç”¨ã—ã¦ã„ã‚‹LLM

- [lmsys/vicuna-7b-v1.5](https://huggingface.co/lmsys/vicuna-7b-v1.5)

##### åˆ©ç”¨ã—ã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

- [HPE Machine Learning Developement Environment (Determined AI)](https://hpe-mlde.determined.ai/latest/)
- [LlamaIndex](https://docs.llamaindex.ai/en/stable/)
- [FastChat](https://github.com/lm-sys/FastChat)
- [Streamlit](https://streamlit.io/)
"""
    )


def llm_query(text):
    start = time.time()

    with st.spinner(text="å›ç­”ç”Ÿæˆä¸­ ..."):
        document_summary_index = CustomDocumentSummaryIndex(openai_api_base="http://fastchat-api-server:8000/v1")

        response = document_summary_index.llm.stream_complete(text)
        result_area = st.empty()
        result = ""

        for item in response:
            result = item.text
            result_area.info(result)

    st.session_state["llm_response"] = result
    st.session_state["llm_response_time"] = time_since(start)

    logging.info(f"Returned LLM response ... {time_since(start)}")


def rag_query(text):
    start = time.time()

    with st.spinner(text="ä»˜åŠ æƒ…å ± æ¤œç´¢ä¸­ ..."):
        document_summary_index = CustomDocumentSummaryIndex(openai_api_base="http://fastchat-api-server:8000/v1")
        document_summary_index.load("/app/rag-system/worker_0_batch_0")
        document_summary_index.as_retriever()

        response = document_summary_index.query(text)

    logging.info(f"Searched addtional infomation ... {time_since(start)}")

    with st.spinner(text="å›ç­”ç”Ÿæˆä¸­ ..."):
        result_area = st.empty()
        result = ""

        for item in response.response_gen:
            result += item
            result_area.info(result)

    st.session_state["rag_response"] = result
    st.session_state["rag_response_time"] = time_since(start)

    logging.info(f"Returned RAG response ... {time_since(start)}")


if __name__ == "__main__":
    main()
