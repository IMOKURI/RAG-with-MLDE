import logging
import time

import streamlit as st

from utils import time_since
from document_summary_index import CustomDocumentSummaryIndex


def main():
    logging.basicConfig(level=logging.INFO)

    st.set_page_config(page_title="ğŸ˜ æ¤œç´¢è£œå®Œç”Ÿæˆãƒ‡ãƒ¢", layout="wide")

    st.title("ğŸ˜ æ¤œç´¢è£œå®Œç”Ÿæˆãƒ‡ãƒ¢")
    st.write(
        "\n"
        "ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€"
        "ã‚ã‚‰ã‹ã˜ã‚å–ã‚Šè¾¼ã¾ã‚ŒãŸè¨˜äº‹ã®æƒ…å ±ã‚’å…ƒã«å›ç­”ã™ã‚‹"
        "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢è£œå®Œç”Ÿæˆ(RAG)ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚"
    )

    with st.form("rag"):
        text = st.text_area("Enter text:", "HPE Swarm Learning ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚")
        submitted = st.form_submit_button("Submit")

        if submitted:
            with st.spinner(text="In progress..."):
                query(text)


def query(text):
    start = time.time()

    document_summary_index = CustomDocumentSummaryIndex(openai_api_base="http://fastchat-api-server:8000/v1")
    document_summary_index.load("/app/rag-system/worker_0_batch_0")
    document_summary_index.as_retriever()

    response = document_summary_index.query(text)

    st.write("LLM Response")
    st.info(response)

    st.write(time_since(start))
    logging.info(f"Returned LLM response ... {time_since(start)}")


if __name__ == "__main__":
    main()
